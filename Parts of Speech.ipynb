{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Using Amazon data set, perform the following: \n",
    "\n",
    "a)Create a bigram TF-IDF DTM using Nouns and proper noun\n",
    "b)Find top 20 words\n",
    "c)Create a cosine similarity matrix using above DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS - Part of Speech tagging - Process in which a sequence of words are tagged with a specific part of speech, based on the context in which it is used in a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First,need to download the following:\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "\n",
    "from nltk import pos_tag,word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#To remove unwanted warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'learning',\n",
       " 'Pos',\n",
       " 'tagging',\n",
       " 'using',\n",
       " 'NLTK']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=word_tokenize(\"Hello welcome to the world of learning Pos tagging using NLTK\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('welcome', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('learning', 'VBG'),\n",
       " ('Pos', 'NNP'),\n",
       " ('tagging', 'VBG'),\n",
       " ('using', 'VBG'),\n",
       " ('NLTK', 'NNP')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'world']\n"
     ]
    }
   ],
   "source": [
    "##finding te noun from above sentence\n",
    "\n",
    "is_noun = lambda x: x ==\"NN\"\n",
    "\n",
    "nouns = [y for (y,x) in pos_tag(text) if is_noun(x)]\n",
    "\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>colors</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>Paperwhite voyage, no regrets!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cristina M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>One Simply Could Not Ask For More</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ricky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id       asins   brand                  categories  \\\n",
       "0  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "1  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "\n",
       "  colors             dateAdded           dateUpdated  \\\n",
       "0    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "1    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "\n",
       "                  dimension  ean                         keys  ...  \\\n",
       "0  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "1  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "\n",
       "  reviews.rating                                 reviews.sourceURLs  \\\n",
       "0            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "1            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "\n",
       "                       reviews.title reviews.userCity  reviews.userProvince  \\\n",
       "0     Paperwhite voyage, no regrets!              NaN                   NaN   \n",
       "1  One Simply Could Not Ask For More              NaN                   NaN   \n",
       "\n",
       "   reviews.username  sizes upc     weight  \n",
       "0        Cristina M    NaN NaN  205 grams  \n",
       "1             Ricky    NaN NaN  205 grams  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the dataset\n",
    "\n",
    "df=pd.read_excel(\"Amazon.xlsx\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the review.text column from the dataframe df\n",
    "\n",
    "df_review=df[[\"reviews.text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I initially had trouble deciding between the paperwhite and the voyage because reviews more or less said the same thing: the paperwhite is great, but if you have spending money, go for the voyage.Fortunately, I had friends who owned each, so I ended up buying the paperwhite on this basis: both models now have 300 ppi, so the 80 dollar jump turns out pricey the voyage's page press isn't always sensitive, and if you are fine with a specific setting, you don't need auto light adjustment).It's been a week and I am loving my paperwhite, no regrets! The touch screen is receptive and easy to use, and I keep the light at a specific setting regardless of the time of day. (In any case, it's not hard to change the setting either, as you'll only be changing the light level at a certain time of day, not every now and then while reading).Also glad that I went for the international shipping option with Amazon. Extra expense, but delivery was on time, with tracking, and I didnt need to worry about customs, which I may have if I used a third party shipping service.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Extracting the first review\n",
    "\n",
    "df_review[\"reviews.text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>lower_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "\n",
       "                                          lower_text  \n",
       "0  i initially had trouble deciding between the p...  \n",
       "1  allow me to preface this with a little history...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step1:Convert  the text into lower case\n",
    "\n",
    "df_review['lower_text']=df_review['reviews.text'].str.lower()\n",
    "df_review.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i initially had trouble deciding between the paperwhite and the voyage because reviews more or less said the same thing the paperwhite is great but if you have spending money go for the voyagefortunately i had friends who owned each so i ended up buying the paperwhite on this basis both models now have  ppi so the  dollar jump turns out pricey the voyage's page press isn't always sensitive and if you are fine with a specific setting you don't need auto light adjustmentit's been a week and i am loving my paperwhite no regrets the touch screen is receptive and easy to use and i keep the light at a specific setting regardless of the time of day in any case it's not hard to change the setting either as you'll only be changing the light level at a certain time of day not every now and then while readingalso glad that i went for the international shipping option with amazon extra expense but delivery was on time with tracking and i didnt need to worry about customs which i may have if i used a third party shipping service\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step2:Removing Punc,special characters etc from the lower_text\n",
    "\n",
    "df_review['new_text']=df_review['lower_text'].str.replace(\"[^a-z' ]\" , \"\")\n",
    "df_review['new_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Removing the stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Create a list of stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"initially trouble deciding paperwhite voyage reviews less said thing paperwhite great spending money go voyagefortunately friends owned ended buying paperwhite basis models ppi dollar jump turns pricey voyage's page press always sensitive fine specific setting need auto light adjustmentit's week loving paperwhite regrets touch screen receptive easy use keep light specific setting regardless time day case hard change setting either changing light level certain time day every readingalso glad went international shipping option amazon extra expense delivery time tracking didnt need worry customs may used third party shipping service\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a user define function to split the text of your review, then do a match of words with the stop list and return the words which are not \n",
    "# present in the stop list\n",
    "\n",
    "def sw(x):\n",
    "    x = [y for y in x.split() if y not in stop]\n",
    "    return \" \".join(x)\n",
    "\n",
    "# Lets apply the UDF sw on the new_text column of the data set\n",
    "\n",
    "df_review['clean_text'] = df_review['new_text'].apply(sw)\n",
    "\n",
    "df_review['clean_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 - Lets create a user define function to apply the POS tags on each word and filter all the nouns\n",
    "\n",
    "def nouns(x):\n",
    "    \n",
    "    # Filter condition using lambda function\n",
    "    \n",
    "    is_noun = lambda x : x == \"NN\"\n",
    "    \n",
    "    # Word tokenizer using word_tokenize()\n",
    "    \n",
    "    token = word_tokenize(x)\n",
    "    \n",
    "    # Apply the pos_tags and filter the nouns\n",
    "    \n",
    "    all_nouns = [y for (y,x) in pos_tag(token) if is_noun(x)]\n",
    "    \n",
    "    # Before returning the words, its should join them to create a \n",
    "    # sentence. Thus: \n",
    "    \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>new_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>initially trouble deciding paperwhite voyage r...</td>\n",
       "      <td>trouble voyage thing paperwhite spending money...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow preface little history casual reader own...</td>\n",
       "      <td>preface history reader touch series girl serie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "\n",
       "                                          lower_text  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "\n",
       "                                            new_text  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  initially trouble deciding paperwhite voyage r...   \n",
       "1  allow preface little history casual reader own...   \n",
       "\n",
       "                                          Final_text  \n",
       "0  trouble voyage thing paperwhite spending money...  \n",
       "1  preface history reader touch series girl serie...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 5 :Lets apply the UDF nouns on the clean_text column of your dataframe(df_text)\n",
    "\n",
    "df_review['Final_text'] = df_review['clean_text'].apply(nouns)\n",
    "\n",
    "df_review.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1597x5001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 31109 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 6 - Creating the BIGRAM DTM\n",
    "\n",
    "# STEP 6.1 - Create a count vectorizer object\n",
    "\n",
    "tfidf_vec_bigram = TfidfVectorizer(min_df=0.001, ngram_range=(2,2))\n",
    "\n",
    "# STEP 6.2 - Fit this count vectorizer object on the clean_text column of dt_text\n",
    "\n",
    "tfidf_vec_bigram.fit(df_review['Final_text'])\n",
    "\n",
    "# STEP 6.3 - Create a DTM by using a command fit_transform\n",
    "\n",
    "DTM_bigram = tfidf_vec_bigram.fit_transform(df_review['Final_text'])\n",
    "\n",
    "DTM_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa aa</th>\n",
       "      <th>aa energizer</th>\n",
       "      <th>ability display</th>\n",
       "      <th>ability download</th>\n",
       "      <th>ability filter</th>\n",
       "      <th>ability plug</th>\n",
       "      <th>ability screen</th>\n",
       "      <th>ability storage</th>\n",
       "      <th>ability stream</th>\n",
       "      <th>ability try</th>\n",
       "      <th>...</th>\n",
       "      <th>year video</th>\n",
       "      <th>year year</th>\n",
       "      <th>youbattery life</th>\n",
       "      <th>youi ereader</th>\n",
       "      <th>youtube chance</th>\n",
       "      <th>youtube fire</th>\n",
       "      <th>youtube hdx</th>\n",
       "      <th>youtube hear</th>\n",
       "      <th>youtube video</th>\n",
       "      <th>youtube videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa aa  aa energizer  ability display  ability download  ability filter  \\\n",
       "0    0.0           0.0              0.0               0.0             0.0   \n",
       "1    0.0           0.0              0.0               0.0             0.0   \n",
       "2    0.0           0.0              0.0               0.0             0.0   \n",
       "3    0.0           0.0              0.0               0.0             0.0   \n",
       "4    0.0           0.0              0.0               0.0             0.0   \n",
       "\n",
       "   ability plug  ability screen  ability storage  ability stream  ability try  \\\n",
       "0           0.0             0.0              0.0             0.0          0.0   \n",
       "1           0.0             0.0              0.0             0.0          0.0   \n",
       "2           0.0             0.0              0.0             0.0          0.0   \n",
       "3           0.0             0.0              0.0             0.0          0.0   \n",
       "4           0.0             0.0              0.0             0.0          0.0   \n",
       "\n",
       "   ...  year video  year year  youbattery life  youi ereader  youtube chance  \\\n",
       "0  ...         0.0        0.0              0.0           0.0             0.0   \n",
       "1  ...         0.0        0.0              0.0           0.0             0.0   \n",
       "2  ...         0.0        0.0              0.0           0.0             0.0   \n",
       "3  ...         0.0        0.0              0.0           0.0             0.0   \n",
       "4  ...         0.0        0.0              0.0           0.0             0.0   \n",
       "\n",
       "   youtube fire  youtube hdx  youtube hear  youtube video  youtube videos  \n",
       "0           0.0          0.0           0.0            0.0             0.0  \n",
       "1           0.0          0.0           0.0            0.0             0.0  \n",
       "2           0.0          0.0           0.0            0.0             0.0  \n",
       "3           0.0          0.0           0.0            0.0             0.0  \n",
       "4           0.0          0.0           0.0            0.0             0.0  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINAL STEP - We will not convert our DTM into a data frame. This can be done by converting the sparse matrix into a array and then passing it\n",
    "# to the pd.DataFrame\n",
    "\n",
    "DTM_BIGRAM_DF = pd.DataFrame(DTM_bigram.toarray(), \n",
    "                      columns = tfidf_vec_bigram.get_feature_names())\n",
    "\n",
    "DTM_BIGRAM_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TERMS</th>\n",
       "      <th>TF_IDF Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>fire hd</td>\n",
       "      <td>27.754811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>apple buds</td>\n",
       "      <td>27.676492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>fire tv</td>\n",
       "      <td>26.147451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>apple tv</td>\n",
       "      <td>16.034167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>kindle fire</td>\n",
       "      <td>14.425060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>fire hdx</td>\n",
       "      <td>14.248908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>battery life</td>\n",
       "      <td>12.984450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>tv tv</td>\n",
       "      <td>12.889196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>star rating</td>\n",
       "      <td>10.845378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>voice search</td>\n",
       "      <td>10.367382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>amazon sound</td>\n",
       "      <td>10.152969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>sound quality</td>\n",
       "      <td>9.851540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>amazon tap</td>\n",
       "      <td>9.781182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>product quality</td>\n",
       "      <td>9.723137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>sound price</td>\n",
       "      <td>9.415850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>price range</td>\n",
       "      <td>9.282290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>validity fall</td>\n",
       "      <td>9.225497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>ignorance apple</td>\n",
       "      <td>9.225497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>something ignorance</td>\n",
       "      <td>9.225497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>stay secure</td>\n",
       "      <td>9.225497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TERMS  TF_IDF Score\n",
       "1600              fire hd     27.754811\n",
       "237            apple buds     27.676492\n",
       "1635              fire tv     26.147451\n",
       "254              apple tv     16.034167\n",
       "2233          kindle fire     14.425060\n",
       "1604             fire hdx     14.248908\n",
       "344          battery life     12.984450\n",
       "4538                tv tv     12.889196\n",
       "4013          star rating     10.845378\n",
       "4759         voice search     10.367382\n",
       "161          amazon sound     10.152969\n",
       "3936        sound quality      9.851540\n",
       "169            amazon tap      9.781182\n",
       "3244      product quality      9.723137\n",
       "3935          sound price      9.415850\n",
       "3174          price range      9.282290\n",
       "4650        validity fall      9.225497\n",
       "2044      ignorance apple      9.225497\n",
       "3889  something ignorance      9.225497\n",
       "4019          stay secure      9.225497"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the Total tfidf score of the words\n",
    "\n",
    "word_tfidf_bigram = DTM_BIGRAM_DF.sum().reset_index()\n",
    "\n",
    "word_tfidf_bigram\n",
    "\n",
    "# Lets rename the columns \n",
    "\n",
    "word_table_bigram = word_tfidf_bigram.rename(columns = {'index' : 'TERMS', \n",
    "                                        0 : 'TF_IDF Score'})\n",
    "\n",
    "word_table_bigram\n",
    "\n",
    "# Finding the top 20 words\n",
    "\n",
    "word_table_bigram.sort_values(by= 'TF_IDF Score', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word similarity using cosine similarity - A commonly usded approach to match similar words.\n",
    "\n",
    "Cosine Similarity: is a matrix to determine how similar a words are. Mathematically, it measures the cosine angle btween two words (which are represented as vectors) in a multi-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.02428543,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.02428543, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets use DTM_BIGRAM_DF to convert this into a square matrix. This can be done my simply passing the transpose of your DTM_BIGRAM_DF into the \n",
    "# function cosine_similarity() which is in library sklearn\n",
    "\n",
    "# lets import the function\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# lets create the cosine similarity matrix\n",
    "\n",
    "sim_mat = cosine_similarity(DTM_BIGRAM_DF.T)\n",
    "\n",
    "sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa aa</th>\n",
       "      <th>aa energizer</th>\n",
       "      <th>ability display</th>\n",
       "      <th>ability download</th>\n",
       "      <th>ability filter</th>\n",
       "      <th>ability plug</th>\n",
       "      <th>ability screen</th>\n",
       "      <th>ability storage</th>\n",
       "      <th>ability stream</th>\n",
       "      <th>ability try</th>\n",
       "      <th>...</th>\n",
       "      <th>year video</th>\n",
       "      <th>year year</th>\n",
       "      <th>youbattery life</th>\n",
       "      <th>youi ereader</th>\n",
       "      <th>youtube chance</th>\n",
       "      <th>youtube fire</th>\n",
       "      <th>youtube hdx</th>\n",
       "      <th>youtube hear</th>\n",
       "      <th>youtube video</th>\n",
       "      <th>youtube videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa aa</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa energizer</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability display</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability download</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103696</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability filter</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aa aa  aa energizer  ability display  ability download  \\\n",
       "aa aa               1.0           1.0         0.000000          0.000000   \n",
       "aa energizer        1.0           1.0         0.000000          0.000000   \n",
       "ability display     0.0           0.0         1.000000          0.234198   \n",
       "ability download    0.0           0.0         0.234198          1.000000   \n",
       "ability filter      0.0           0.0         0.000000          0.000000   \n",
       "\n",
       "                  ability filter  ability plug  ability screen  \\\n",
       "aa aa                        0.0           0.0             0.0   \n",
       "aa energizer                 0.0           0.0             0.0   \n",
       "ability display              0.0           0.0             0.0   \n",
       "ability download             0.0           0.0             0.0   \n",
       "ability filter               1.0           0.0             0.0   \n",
       "\n",
       "                  ability storage  ability stream  ability try  ...  \\\n",
       "aa aa                         0.0             0.0          0.0  ...   \n",
       "aa energizer                  0.0             0.0          0.0  ...   \n",
       "ability display               0.0             0.0          0.0  ...   \n",
       "ability download              0.0             0.0          0.0  ...   \n",
       "ability filter                0.0             0.0          0.0  ...   \n",
       "\n",
       "                  year video  year year  youbattery life  youi ereader  \\\n",
       "aa aa                    0.0        0.0         0.000000           0.0   \n",
       "aa energizer             0.0        0.0         0.000000           0.0   \n",
       "ability display          0.0        0.0         0.234198           0.0   \n",
       "ability download         0.0        0.0         1.000000           0.0   \n",
       "ability filter           0.0        0.0         0.000000           0.0   \n",
       "\n",
       "                  youtube chance  youtube fire  youtube hdx  youtube hear  \\\n",
       "aa aa                        0.0           0.0     0.000000           0.0   \n",
       "aa energizer                 0.0           0.0     0.000000           0.0   \n",
       "ability display              0.0           0.0     0.024285           0.0   \n",
       "ability download             0.0           0.0     0.103696           0.0   \n",
       "ability filter               0.0           0.0     0.000000           0.0   \n",
       "\n",
       "                  youtube video  youtube videos  \n",
       "aa aa                  0.000000             0.0  \n",
       "aa energizer           0.000000             0.0  \n",
       "ability display        0.024285             0.0  \n",
       "ability download       0.103696             0.0  \n",
       "ability filter         0.000000             0.0  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets convert this sim_mat square matrix into a data frame\n",
    "\n",
    "sim_df = pd.DataFrame(sim_mat, columns = DTM_BIGRAM_DF.columns, \n",
    "                     index = DTM_BIGRAM_DF.columns)\n",
    "\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user define function\n",
    "\n",
    "def get_similar_words(input_word, sim_mat_df, n_words):\n",
    "    \n",
    "    # For a given input words it will find the similarity score and will\n",
    "    # arrange the same from highest to lowest\n",
    "    \n",
    "    val = sim_mat_df[input_word].sort_values(ascending = False)\n",
    "    \n",
    "    # I should drop the input word from final list\n",
    "    \n",
    "    words = val.drop(input_word).head(n_words)\n",
    "    \n",
    "    # Returning the list of words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire hd            0.601994\n",
       "year hd            0.585267\n",
       "fire kindle        0.550263\n",
       "hd year            0.550175\n",
       "hd fire            0.543074\n",
       "business tablet    0.512349\n",
       "device review      0.508924\n",
       "comparison sake    0.508857\n",
       "ghz quad           0.508857\n",
       "keyboard nexus     0.508857\n",
       "year comparison    0.508857\n",
       "content year       0.508857\n",
       "goto device        0.508857\n",
       "quad processor     0.508857\n",
       "hd keyboard        0.508857\n",
       "hdx play           0.508857\n",
       "internet search    0.508857\n",
       "tablet day         0.508857\n",
       "play ghz           0.508857\n",
       "year video         0.508857\n",
       "Name: kindle fire, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets find the top 20 words \n",
    "\n",
    "get_similar_words(\"kindle fire\",sim_df,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END ####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
